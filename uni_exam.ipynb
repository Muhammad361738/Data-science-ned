{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 D array  [1 2 3 4 5]\n",
      "2D Array  [[ 1  2  3  4  5]\n",
      " [ 6  7  8  9 10]]\n",
      "2D Array  [[ 1  2  3  4  5]\n",
      " [ 6  7  8  9 10]\n",
      " [11 12 13 14 15]]\n"
     ]
    }
   ],
   "source": [
    "# Creating array from List\n",
    "arr_id=np.array([1,2,3,4,5])\n",
    "print(\"1 D array \", arr_id)\n",
    "\n",
    "arr_2d=np.array([[1,2,3,4,5],[6,7,8,9,10]])\n",
    "print(\"2D Array \", arr_2d) \n",
    "\n",
    "arr_3d=np.array([[1,2,3,4,5],[6,7,8,9,10],[11,12,13,14,15]])\n",
    "print(\"2D Array \", arr_3d) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zero Array , [[0. 0. 0.]\n",
      " [0. 0. 0.]]\n",
      "Ones Array , [[1. 1. 1.]\n",
      " [1. 1. 1.]]\n"
     ]
    }
   ],
   "source": [
    "arr=np.zeros([2,3])\n",
    "print(\"Zero Array ,\",arr)\n",
    "arr=np.ones([2,3])\n",
    "print(\"Ones Array ,\",arr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 to 20  [ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20]\n"
     ]
    }
   ],
   "source": [
    "arr=np.arange(1,21)\n",
    "print(\"1 to 20 \",arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape  (2, 3)\n",
      "Shape  6\n"
     ]
    }
   ],
   "source": [
    "arr = np.array([[3, 5, 7], [2, 4, 6]])\n",
    "print(\"Shape \",arr.shape)\n",
    "print(\"Shape \",arr.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data type float64\n"
     ]
    }
   ],
   "source": [
    "arr = np.array([1.0, 2.0, 3.0])\n",
    "print(\"data type\",arr.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reshape [[ 0  1  2  3]\n",
      " [ 4  5  6  7]\n",
      " [ 8  9 10 11]]\n"
     ]
    }
   ],
   "source": [
    "arr=np.arange(12)\n",
    "print(\"reshape\",arr.reshape(3,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean 30.0\n",
      "median 30.0\n",
      "standard 14.142135623730951\n"
     ]
    }
   ],
   "source": [
    "# 6. Find mean, median, and standard deviation\n",
    "\n",
    "arr = np.array([10, 20, 30, 40, 50])\n",
    "print(\"mean\",np.mean(arr))\n",
    "print(\"median\",np.median(arr))\n",
    "print(\"standard\",np.std(arr))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 0. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 0. 0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "# 7. Create an identity matrix of size 4x4\n",
    "\n",
    "identity=np.eye(4)\n",
    "print(identity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Verticle  [[10 12]\n",
      " [13 14]\n",
      " [15 16]\n",
      " [17 18]]\n",
      "horizontal  [[10 12 15 16]\n",
      " [13 14 17 18]]\n"
     ]
    }
   ],
   "source": [
    "# 8. Stack two arrays vertically and horizontally\n",
    "a=np.array([[10,12],[13,14]])\n",
    "b=np.array([[15,16],[17,18]])\n",
    "\n",
    "print(\"Verticle \",np.vstack((a,b)))\n",
    "print(\"horizontal \",np.hstack((a,b)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "75\n"
     ]
    }
   ],
   "source": [
    "a=np.array([1,2,3,45,69,75,2])\n",
    "print(a.min())\n",
    "print(a.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 2  4  6  8 10]\n"
     ]
    }
   ],
   "source": [
    "a=np.arange(1,11)\n",
    "even=a[a%2==0]\n",
    "print(even)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[25 28]\n",
      " [73 82]]\n"
     ]
    }
   ],
   "source": [
    "a=np.array([[1,2],[4,5]])\n",
    "b=np.array([[7,8],[9,10]])\n",
    "dot_product=np.dot(a,b)\n",
    "print(dot_product)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 1. 1. 1. 1.]\n",
      " [1. 0. 0. 0. 1.]\n",
      " [1. 0. 0. 0. 1.]\n",
      " [1. 0. 0. 0. 1.]\n",
      " [1. 1. 1. 1. 1.]]\n"
     ]
    }
   ],
   "source": [
    "arr = np.ones((5, 5))\n",
    "arr[1:-1, 1:-1] = 0\n",
    "print(arr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrix:\n",
      " [[0.40649142 0.5356546  0.93826269]\n",
      " [0.70200451 0.48964472 0.90922213]\n",
      " [0.83689564 0.7686004  0.3028193 ]]\n",
      "Determinant: 0.19169418464207286\n"
     ]
    }
   ],
   "source": [
    "matrix = np.random.rand(3, 3)\n",
    "print(\"Matrix:\\n\", matrix)\n",
    "\n",
    "det = np.linalg.det(matrix)\n",
    "print(\"Determinant:\", det)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 4  4]\n",
      " [10  8]]\n"
     ]
    }
   ],
   "source": [
    "a = np.array([[1, 2], [3, 4]])\n",
    "b = np.array([[2, 0], [1, 2]])\n",
    "my_dot= np.dot(a, b)\n",
    "print(my_dot)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1: Load the Dataset\n",
    "1. Load the CSV file using np.genfromtxt() or np.loadtxt() (skip the header if needed).\n",
    "2. Slice out the numerical columns into a separate NumPy array (4 features only).\n",
    "3. Print the shape of the resulting NumPy array.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of numerical data: (149, 4)\n"
     ]
    }
   ],
   "source": [
    "# import numpy as np\n",
    "\n",
    "# # 1. Load the CSV file (skip the header if needed)\n",
    "# data = np.genfromtxt('iris.csv', delimiter=',', skip_header=1)\n",
    "\n",
    "# # 2. Slice out the numerical columns (first 4 features only)\n",
    "# numerical_data = data[:, :4]  # assuming first 4 columns are numerical\n",
    "\n",
    "# # 3. Print the shape of the resulting array\n",
    "# print(\"Shape of numerical data:\", numerical_data.shape)\n",
    "\n",
    "# Ye function bhi text ya CSV file se data load karta hai, lekin zyada smart hai:\n",
    "\n",
    "# Ye missing values ko handle kar sakta hai.\n",
    "\n",
    "# Ye header ko skip kar sakta hai.\n",
    "\n",
    "# Ye mixed data (jaise kuch columns text aur kuch numbers) bhi handle kar leta hai\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4.9 3.  1.4 0.2 nan]\n",
      " [4.7 3.2 1.3 0.2 nan]\n",
      " [4.6 3.1 1.5 0.2 nan]\n",
      " [5.  3.6 1.4 0.2 nan]\n",
      " [5.4 3.9 1.7 0.4 nan]\n",
      " [4.6 3.4 1.4 0.3 nan]\n",
      " [5.  3.4 1.5 0.2 nan]\n",
      " [4.4 2.9 1.4 0.2 nan]\n",
      " [4.9 3.1 1.5 0.1 nan]\n",
      " [5.4 3.7 1.5 0.2 nan]\n",
      " [4.8 3.4 1.6 0.2 nan]\n",
      " [4.8 3.  1.4 0.1 nan]\n",
      " [4.3 3.  1.1 0.1 nan]\n",
      " [5.8 4.  1.2 0.2 nan]\n",
      " [5.7 4.4 1.5 0.4 nan]\n",
      " [5.4 3.9 1.3 0.4 nan]\n",
      " [5.1 3.5 1.4 0.3 nan]\n",
      " [5.7 3.8 1.7 0.3 nan]\n",
      " [5.1 3.8 1.5 0.3 nan]\n",
      " [5.4 3.4 1.7 0.2 nan]\n",
      " [5.1 3.7 1.5 0.4 nan]\n",
      " [4.6 3.6 1.  0.2 nan]\n",
      " [5.1 3.3 1.7 0.5 nan]\n",
      " [4.8 3.4 1.9 0.2 nan]\n",
      " [5.  3.  1.6 0.2 nan]\n",
      " [5.  3.4 1.6 0.4 nan]\n",
      " [5.2 3.5 1.5 0.2 nan]\n",
      " [5.2 3.4 1.4 0.2 nan]\n",
      " [4.7 3.2 1.6 0.2 nan]\n",
      " [4.8 3.1 1.6 0.2 nan]\n",
      " [5.4 3.4 1.5 0.4 nan]\n",
      " [5.2 4.1 1.5 0.1 nan]\n",
      " [5.5 4.2 1.4 0.2 nan]\n",
      " [4.9 3.1 1.5 0.1 nan]\n",
      " [5.  3.2 1.2 0.2 nan]\n",
      " [5.5 3.5 1.3 0.2 nan]\n",
      " [4.9 3.1 1.5 0.1 nan]\n",
      " [4.4 3.  1.3 0.2 nan]\n",
      " [5.1 3.4 1.5 0.2 nan]\n",
      " [5.  3.5 1.3 0.3 nan]\n",
      " [4.5 2.3 1.3 0.3 nan]\n",
      " [4.4 3.2 1.3 0.2 nan]\n",
      " [5.  3.5 1.6 0.6 nan]\n",
      " [5.1 3.8 1.9 0.4 nan]\n",
      " [4.8 3.  1.4 0.3 nan]\n",
      " [5.1 3.8 1.6 0.2 nan]\n",
      " [4.6 3.2 1.4 0.2 nan]\n",
      " [5.3 3.7 1.5 0.2 nan]\n",
      " [5.  3.3 1.4 0.2 nan]\n",
      " [7.  3.2 4.7 1.4 nan]\n",
      " [6.4 3.2 4.5 1.5 nan]\n",
      " [6.9 3.1 4.9 1.5 nan]\n",
      " [5.5 2.3 4.  1.3 nan]\n",
      " [6.5 2.8 4.6 1.5 nan]\n",
      " [5.7 2.8 4.5 1.3 nan]\n",
      " [6.3 3.3 4.7 1.6 nan]\n",
      " [4.9 2.4 3.3 1.  nan]\n",
      " [6.6 2.9 4.6 1.3 nan]\n",
      " [5.2 2.7 3.9 1.4 nan]\n",
      " [5.  2.  3.5 1.  nan]\n",
      " [5.9 3.  4.2 1.5 nan]\n",
      " [6.  2.2 4.  1.  nan]\n",
      " [6.1 2.9 4.7 1.4 nan]\n",
      " [5.6 2.9 3.6 1.3 nan]\n",
      " [6.7 3.1 4.4 1.4 nan]\n",
      " [5.6 3.  4.5 1.5 nan]\n",
      " [5.8 2.7 4.1 1.  nan]\n",
      " [6.2 2.2 4.5 1.5 nan]\n",
      " [5.6 2.5 3.9 1.1 nan]\n",
      " [5.9 3.2 4.8 1.8 nan]\n",
      " [6.1 2.8 4.  1.3 nan]\n",
      " [6.3 2.5 4.9 1.5 nan]\n",
      " [6.1 2.8 4.7 1.2 nan]\n",
      " [6.4 2.9 4.3 1.3 nan]\n",
      " [6.6 3.  4.4 1.4 nan]\n",
      " [6.8 2.8 4.8 1.4 nan]\n",
      " [6.7 3.  5.  1.7 nan]\n",
      " [6.  2.9 4.5 1.5 nan]\n",
      " [5.7 2.6 3.5 1.  nan]\n",
      " [5.5 2.4 3.8 1.1 nan]\n",
      " [5.5 2.4 3.7 1.  nan]\n",
      " [5.8 2.7 3.9 1.2 nan]\n",
      " [6.  2.7 5.1 1.6 nan]\n",
      " [5.4 3.  4.5 1.5 nan]\n",
      " [6.  3.4 4.5 1.6 nan]\n",
      " [6.7 3.1 4.7 1.5 nan]\n",
      " [6.3 2.3 4.4 1.3 nan]\n",
      " [5.6 3.  4.1 1.3 nan]\n",
      " [5.5 2.5 4.  1.3 nan]\n",
      " [5.5 2.6 4.4 1.2 nan]\n",
      " [6.1 3.  4.6 1.4 nan]\n",
      " [5.8 2.6 4.  1.2 nan]\n",
      " [5.  2.3 3.3 1.  nan]\n",
      " [5.6 2.7 4.2 1.3 nan]\n",
      " [5.7 3.  4.2 1.2 nan]\n",
      " [5.7 2.9 4.2 1.3 nan]\n",
      " [6.2 2.9 4.3 1.3 nan]\n",
      " [5.1 2.5 3.  1.1 nan]\n",
      " [5.7 2.8 4.1 1.3 nan]\n",
      " [6.3 3.3 6.  2.5 nan]\n",
      " [5.8 2.7 5.1 1.9 nan]\n",
      " [7.1 3.  5.9 2.1 nan]\n",
      " [6.3 2.9 5.6 1.8 nan]\n",
      " [6.5 3.  5.8 2.2 nan]\n",
      " [7.6 3.  6.6 2.1 nan]\n",
      " [4.9 2.5 4.5 1.7 nan]\n",
      " [7.3 2.9 6.3 1.8 nan]\n",
      " [6.7 2.5 5.8 1.8 nan]\n",
      " [7.2 3.6 6.1 2.5 nan]\n",
      " [6.5 3.2 5.1 2.  nan]\n",
      " [6.4 2.7 5.3 1.9 nan]\n",
      " [6.8 3.  5.5 2.1 nan]\n",
      " [5.7 2.5 5.  2.  nan]\n",
      " [5.8 2.8 5.1 2.4 nan]\n",
      " [6.4 3.2 5.3 2.3 nan]\n",
      " [6.5 3.  5.5 1.8 nan]\n",
      " [7.7 3.8 6.7 2.2 nan]\n",
      " [7.7 2.6 6.9 2.3 nan]\n",
      " [6.  2.2 5.  1.5 nan]\n",
      " [6.9 3.2 5.7 2.3 nan]\n",
      " [5.6 2.8 4.9 2.  nan]\n",
      " [7.7 2.8 6.7 2.  nan]\n",
      " [6.3 2.7 4.9 1.8 nan]\n",
      " [6.7 3.3 5.7 2.1 nan]\n",
      " [7.2 3.2 6.  1.8 nan]\n",
      " [6.2 2.8 4.8 1.8 nan]\n",
      " [6.1 3.  4.9 1.8 nan]\n",
      " [6.4 2.8 5.6 2.1 nan]\n",
      " [7.2 3.  5.8 1.6 nan]\n",
      " [7.4 2.8 6.1 1.9 nan]\n",
      " [7.9 3.8 6.4 2.  nan]\n",
      " [6.4 2.8 5.6 2.2 nan]\n",
      " [6.3 2.8 5.1 1.5 nan]\n",
      " [6.1 2.6 5.6 1.4 nan]\n",
      " [7.7 3.  6.1 2.3 nan]\n",
      " [6.3 3.4 5.6 2.4 nan]\n",
      " [6.4 3.1 5.5 1.8 nan]\n",
      " [6.  3.  4.8 1.8 nan]\n",
      " [6.9 3.1 5.4 2.1 nan]\n",
      " [6.7 3.1 5.6 2.4 nan]\n",
      " [6.9 3.1 5.1 2.3 nan]\n",
      " [5.8 2.7 5.1 1.9 nan]\n",
      " [6.8 3.2 5.9 2.3 nan]\n",
      " [6.7 3.3 5.7 2.5 nan]\n",
      " [6.7 3.  5.2 2.3 nan]\n",
      " [6.3 2.5 5.  1.9 nan]\n",
      " [6.5 3.  5.2 2.  nan]\n",
      " [6.2 3.4 5.4 2.3 nan]\n",
      " [5.9 3.  5.1 1.8 nan]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "data = np.genfromtxt('iris.csv', delimiter=',', skip_header=1)\n",
    "print(data)\n",
    "num"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2: Basic Array Operations\n",
    "1. Compute the mean, max, and min for each column.\n",
    "2. Calculate the standard deviation and variance for the dataset.\n",
    "3. Normalize the data using Z-score normalization:\n",
    "z=xâˆ’Î¼Ïƒz = \\frac{x - \\mu}{\\sigma}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numerical data (first 5 rows): [[5.1 3.5 1.4 0.2]\n",
      " [4.9 3.  1.4 0.2]\n",
      " [4.7 3.2 1.3 0.2]\n",
      " [4.6 3.1 1.5 0.2]\n",
      " [5.  3.6 1.4 0.2]]\n",
      "Column-wise Mean: [5.84333333 3.054      3.75866667 1.19866667]\n",
      "Column-wise Max: [7.9 4.4 6.9 2.5]\n",
      "Column-wise Min: [4.3 2.  1.  0.1]\n",
      "Standard Deviation: [0.82530129 0.43214658 1.75852918 0.76061262]\n",
      "Variance: [0.68112222 0.18675067 3.09242489 0.57853156]\n",
      "Z-score Normalized Data (first 5 rows):\n",
      " [[-0.90068117  1.03205722 -1.3412724  -1.31297673]\n",
      " [-1.14301691 -0.1249576  -1.3412724  -1.31297673]\n",
      " [-1.38535265  0.33784833 -1.39813811 -1.31297673]\n",
      " [-1.50652052  0.10644536 -1.2844067  -1.31297673]\n",
      " [-1.02184904  1.26346019 -1.3412724  -1.31297673]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Load the CSV file (specifically using dtype=float for numerical values)\n",
    "data = np.genfromtxt('iris.csv', delimiter=',', skip_header=0, usecols=(0, 1, 2, 3), dtype=float)\n",
    "\n",
    "# Verify data has been correctly loaded (first 5 rows)\n",
    "print(\"Numerical data (first 5 rows):\", data[:5])\n",
    "\n",
    "# 1. Mean, Max, Min for each column\n",
    "means = np.mean(data, axis=0)\n",
    "max_vals = np.max(data, axis=0)\n",
    "min_vals = np.min(data, axis=0)\n",
    "\n",
    "print(\"Column-wise Mean:\", means)\n",
    "print(\"Column-wise Max:\", max_vals)\n",
    "print(\"Column-wise Min:\", min_vals)\n",
    "\n",
    "# 2. Standard Deviation and Variance\n",
    "std_dev = np.std(data, axis=0)\n",
    "variance = np.var(data, axis=0)\n",
    "\n",
    "print(\"Standard Deviation:\", std_dev)\n",
    "print(\"Variance:\", variance)\n",
    "\n",
    "# 3. Z-score Normalization\n",
    "z_normalized = (data - means) / std_dev\n",
    "\n",
    "print(\"Z-score Normalized Data (first 5 rows):\\n\", z_normalized[:5])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3: Indexing and Slicing\n",
    "1. Extract only the Sepal Length column.\n",
    "2. Get the values for the first 10 flowers.\n",
    "3. Extract flowers where Petal Length > 1.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sepal Length (first 5 rows): [5.1 4.9 4.7 4.6 5. ]\n",
      "First 10 Flowers (features):\n",
      " [[5.1 3.5 1.4 0.2]\n",
      " [4.9 3.  1.4 0.2]\n",
      " [4.7 3.2 1.3 0.2]\n",
      " [4.6 3.1 1.5 0.2]\n",
      " [5.  3.6 1.4 0.2]\n",
      " [5.4 3.9 1.7 0.4]\n",
      " [4.6 3.4 1.4 0.3]\n",
      " [5.  3.4 1.5 0.2]\n",
      " [4.4 2.9 1.4 0.2]\n",
      " [4.9 3.1 1.5 0.1]]\n",
      "Flowers with Petal Length > 1.5:\n",
      " [[5.4 3.9 1.7 0.4]\n",
      " [4.8 3.4 1.6 0.2]\n",
      " [5.7 3.8 1.7 0.3]\n",
      " [5.4 3.4 1.7 0.2]\n",
      " [5.1 3.3 1.7 0.5]\n",
      " [4.8 3.4 1.9 0.2]\n",
      " [5.  3.  1.6 0.2]\n",
      " [5.  3.4 1.6 0.4]\n",
      " [4.7 3.2 1.6 0.2]\n",
      " [4.8 3.1 1.6 0.2]\n",
      " [5.  3.5 1.6 0.6]\n",
      " [5.1 3.8 1.9 0.4]\n",
      " [5.1 3.8 1.6 0.2]\n",
      " [7.  3.2 4.7 1.4]\n",
      " [6.4 3.2 4.5 1.5]\n",
      " [6.9 3.1 4.9 1.5]\n",
      " [5.5 2.3 4.  1.3]\n",
      " [6.5 2.8 4.6 1.5]\n",
      " [5.7 2.8 4.5 1.3]\n",
      " [6.3 3.3 4.7 1.6]\n",
      " [4.9 2.4 3.3 1. ]\n",
      " [6.6 2.9 4.6 1.3]\n",
      " [5.2 2.7 3.9 1.4]\n",
      " [5.  2.  3.5 1. ]\n",
      " [5.9 3.  4.2 1.5]\n",
      " [6.  2.2 4.  1. ]\n",
      " [6.1 2.9 4.7 1.4]\n",
      " [5.6 2.9 3.6 1.3]\n",
      " [6.7 3.1 4.4 1.4]\n",
      " [5.6 3.  4.5 1.5]\n",
      " [5.8 2.7 4.1 1. ]\n",
      " [6.2 2.2 4.5 1.5]\n",
      " [5.6 2.5 3.9 1.1]\n",
      " [5.9 3.2 4.8 1.8]\n",
      " [6.1 2.8 4.  1.3]\n",
      " [6.3 2.5 4.9 1.5]\n",
      " [6.1 2.8 4.7 1.2]\n",
      " [6.4 2.9 4.3 1.3]\n",
      " [6.6 3.  4.4 1.4]\n",
      " [6.8 2.8 4.8 1.4]\n",
      " [6.7 3.  5.  1.7]\n",
      " [6.  2.9 4.5 1.5]\n",
      " [5.7 2.6 3.5 1. ]\n",
      " [5.5 2.4 3.8 1.1]\n",
      " [5.5 2.4 3.7 1. ]\n",
      " [5.8 2.7 3.9 1.2]\n",
      " [6.  2.7 5.1 1.6]\n",
      " [5.4 3.  4.5 1.5]\n",
      " [6.  3.4 4.5 1.6]\n",
      " [6.7 3.1 4.7 1.5]\n",
      " [6.3 2.3 4.4 1.3]\n",
      " [5.6 3.  4.1 1.3]\n",
      " [5.5 2.5 4.  1.3]\n",
      " [5.5 2.6 4.4 1.2]\n",
      " [6.1 3.  4.6 1.4]\n",
      " [5.8 2.6 4.  1.2]\n",
      " [5.  2.3 3.3 1. ]\n",
      " [5.6 2.7 4.2 1.3]\n",
      " [5.7 3.  4.2 1.2]\n",
      " [5.7 2.9 4.2 1.3]\n",
      " [6.2 2.9 4.3 1.3]\n",
      " [5.1 2.5 3.  1.1]\n",
      " [5.7 2.8 4.1 1.3]\n",
      " [6.3 3.3 6.  2.5]\n",
      " [5.8 2.7 5.1 1.9]\n",
      " [7.1 3.  5.9 2.1]\n",
      " [6.3 2.9 5.6 1.8]\n",
      " [6.5 3.  5.8 2.2]\n",
      " [7.6 3.  6.6 2.1]\n",
      " [4.9 2.5 4.5 1.7]\n",
      " [7.3 2.9 6.3 1.8]\n",
      " [6.7 2.5 5.8 1.8]\n",
      " [7.2 3.6 6.1 2.5]\n",
      " [6.5 3.2 5.1 2. ]\n",
      " [6.4 2.7 5.3 1.9]\n",
      " [6.8 3.  5.5 2.1]\n",
      " [5.7 2.5 5.  2. ]\n",
      " [5.8 2.8 5.1 2.4]\n",
      " [6.4 3.2 5.3 2.3]\n",
      " [6.5 3.  5.5 1.8]\n",
      " [7.7 3.8 6.7 2.2]\n",
      " [7.7 2.6 6.9 2.3]\n",
      " [6.  2.2 5.  1.5]\n",
      " [6.9 3.2 5.7 2.3]\n",
      " [5.6 2.8 4.9 2. ]\n",
      " [7.7 2.8 6.7 2. ]\n",
      " [6.3 2.7 4.9 1.8]\n",
      " [6.7 3.3 5.7 2.1]\n",
      " [7.2 3.2 6.  1.8]\n",
      " [6.2 2.8 4.8 1.8]\n",
      " [6.1 3.  4.9 1.8]\n",
      " [6.4 2.8 5.6 2.1]\n",
      " [7.2 3.  5.8 1.6]\n",
      " [7.4 2.8 6.1 1.9]\n",
      " [7.9 3.8 6.4 2. ]\n",
      " [6.4 2.8 5.6 2.2]\n",
      " [6.3 2.8 5.1 1.5]\n",
      " [6.1 2.6 5.6 1.4]\n",
      " [7.7 3.  6.1 2.3]\n",
      " [6.3 3.4 5.6 2.4]\n",
      " [6.4 3.1 5.5 1.8]\n",
      " [6.  3.  4.8 1.8]\n",
      " [6.9 3.1 5.4 2.1]\n",
      " [6.7 3.1 5.6 2.4]\n",
      " [6.9 3.1 5.1 2.3]\n",
      " [5.8 2.7 5.1 1.9]\n",
      " [6.8 3.2 5.9 2.3]\n",
      " [6.7 3.3 5.7 2.5]\n",
      " [6.7 3.  5.2 2.3]\n",
      " [6.3 2.5 5.  1.9]\n",
      " [6.5 3.  5.2 2. ]\n",
      " [6.2 3.4 5.4 2.3]\n",
      " [5.9 3.  5.1 1.8]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Load the CSV file \n",
    "data = np.genfromtxt('iris.csv', delimiter=',', skip_header=0, usecols=(0, 1, 2, 3), dtype=float)\n",
    "\n",
    "# 1. Extract only the Sepal Length column (first column)\n",
    "sepal_length = data[:, 0]  # First column (Sepal Length)\n",
    "print(\"Sepal Length (first 5 rows):\", sepal_length[:5])\n",
    "\n",
    "# 2. Get the values for the first 10 flowers\n",
    "first_10_flowers = data[:10, :]  # First 10 rows (all columns)\n",
    "print(\"First 10 Flowers (features):\\n\", first_10_flowers)\n",
    "\n",
    "# 3. Extract flowers where Petal Length > 1.5\n",
    "petal_length_column = data[:, 2]  # Petal Length is the 3rd column (index 2)\n",
    "flowers_with_petal_length_gt_1_5 = data[petal_length_column > 1.5, :]\n",
    "print(\"Flowers with Petal Length > 1.5:\\n\", flowers_with_petal_length_gt_1_5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 4: Advanced Operations\n",
    "1. Find the Euclidean distance between the first two rows.\n",
    "2. Count how many flowers have Sepal Width greater than the mean.\n",
    "3. Multiply two columns element-wise (e.g., SepalLength * PetalLength)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Euclidean distance between the first two rows: 0.5385164807134502\n",
      "Number of flowers with Sepal Width greater than the mean: 67\n",
      "Element-wise product of Sepal Length and Petal Length (first 5 rows): [7.14 6.86 6.11 6.9  7.  ]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Load the CSV file (assuming data is already loaded correctly)\n",
    "data = np.genfromtxt('iris.csv', delimiter=',', skip_header=0, usecols=(0, 1, 2, 3), dtype=float)\n",
    "\n",
    "# 1. Find the Euclidean distance between the first two rows\n",
    "def euclidean_distance(row1, row2):\n",
    "    return np.sqrt(np.sum((row1 - row2) ** 2))\n",
    "\n",
    "# Extract first two rows\n",
    "row1 = data[0, :]\n",
    "row2 = data[1, :]\n",
    "\n",
    "distance = euclidean_distance(row1, row2)\n",
    "print(f\"Euclidean distance between the first two rows: {distance}\")\n",
    "\n",
    "# 2. Count how many flowers have Sepal Width greater than the mean\n",
    "sepal_width_column = data[:, 1]  # Sepal Width is the 2nd column (index 1)\n",
    "mean_sepal_width = np.mean(sepal_width_column)\n",
    "\n",
    "# Count how many values are greater than the mean\n",
    "flowers_greater_than_mean = np.sum(sepal_width_column > mean_sepal_width)\n",
    "print(f\"Number of flowers with Sepal Width greater than the mean: {flowers_greater_than_mean}\")\n",
    "\n",
    "# 3. Multiply two columns element-wise (e.g., SepalLength * PetalLength)\n",
    "sepal_length_column = data[:, 0]  # Sepal Length is the 1st column (index 0)\n",
    "petal_length_column = data[:, 2]  # Petal Length is the 3rd column (index 2)\n",
    "\n",
    "# Element-wise multiplication\n",
    "sepal_petal_product = sepal_length_column * petal_length_column\n",
    "print(f\"Element-wise product of Sepal Length and Petal Length (first 5 rows): {sepal_petal_product[:5]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 5: Array Reshaping and Stacking\n",
    "1. Reshape the array to simulate batches of size 30.\n",
    "2. Stack two feature columns horizontally.\n",
    "3. Create a boolean mask to filter rows with Petal Width < 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reshaped data to batches of size 30 (first batch):\n",
      " [[5.1 3.5 1.4 0.2]\n",
      " [4.9 3.  1.4 0.2]\n",
      " [4.7 3.2 1.3 0.2]\n",
      " [4.6 3.1 1.5 0.2]\n",
      " [5.  3.6 1.4 0.2]\n",
      " [5.4 3.9 1.7 0.4]\n",
      " [4.6 3.4 1.4 0.3]\n",
      " [5.  3.4 1.5 0.2]\n",
      " [4.4 2.9 1.4 0.2]\n",
      " [4.9 3.1 1.5 0.1]\n",
      " [5.4 3.7 1.5 0.2]\n",
      " [4.8 3.4 1.6 0.2]\n",
      " [4.8 3.  1.4 0.1]\n",
      " [4.3 3.  1.1 0.1]\n",
      " [5.8 4.  1.2 0.2]\n",
      " [5.7 4.4 1.5 0.4]\n",
      " [5.4 3.9 1.3 0.4]\n",
      " [5.1 3.5 1.4 0.3]\n",
      " [5.7 3.8 1.7 0.3]\n",
      " [5.1 3.8 1.5 0.3]\n",
      " [5.4 3.4 1.7 0.2]\n",
      " [5.1 3.7 1.5 0.4]\n",
      " [4.6 3.6 1.  0.2]\n",
      " [5.1 3.3 1.7 0.5]\n",
      " [4.8 3.4 1.9 0.2]\n",
      " [5.  3.  1.6 0.2]\n",
      " [5.  3.4 1.6 0.4]\n",
      " [5.2 3.5 1.5 0.2]\n",
      " [5.2 3.4 1.4 0.2]\n",
      " [4.7 3.2 1.6 0.2]]\n",
      "Stacked Sepal Length and Sepal Width (first 5 rows):\n",
      " [[5.1 3.5]\n",
      " [4.9 3. ]\n",
      " [4.7 3.2]\n",
      " [4.6 3.1]\n",
      " [5.  3.6]]\n",
      "Rows where Petal Width < 0.5 (first 5 rows):\n",
      " [[5.1 3.5 1.4 0.2]\n",
      " [4.9 3.  1.4 0.2]\n",
      " [4.7 3.2 1.3 0.2]\n",
      " [4.6 3.1 1.5 0.2]\n",
      " [5.  3.6 1.4 0.2]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Load the CSV file (assuming it's already loaded correctly)\n",
    "data = np.genfromtxt('iris.csv', delimiter=',', skip_header=0, usecols=(0, 1, 2, 3), dtype=float)\n",
    "\n",
    "# 1. Reshape the array to simulate batches of size 30\n",
    "# We have 150 rows, so we can reshape the data to (5, 30, 4), where 5 is the number of batches, 30 is the batch size, and 4 is the number of features per row.\n",
    "reshaped_data = np.reshape(data, (5, 30, 4))  # Shape will be (5, 30, 4)\n",
    "print(f\"Reshaped data to batches of size 30 (first batch):\\n {reshaped_data[0]}\")\n",
    "\n",
    "# 2. Stack two feature columns horizontally (e.g., Sepal Length and Sepal Width)\n",
    "sepal_length_column = data[:, 0]  # Sepal Length (1st column)\n",
    "sepal_width_column = data[:, 1]   # Sepal Width (2nd column)\n",
    "\n",
    "stacked_columns = np.column_stack((sepal_length_column, sepal_width_column))\n",
    "print(f\"Stacked Sepal Length and Sepal Width (first 5 rows):\\n {stacked_columns[:5]}\")\n",
    "\n",
    "# 3. Create a boolean mask to filter rows with Petal Width < 0.5\n",
    "petal_width_column = data[:, 3]  # Petal Width (4th column)\n",
    "\n",
    "# Create a boolean mask\n",
    "mask = petal_width_column < 0.5\n",
    "filtered_data = data[mask, :]\n",
    "print(f\"Rows where Petal Width < 0.5 (first 5 rows):\\n {filtered_data[:5]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BFS lab "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Goal 4 found!\n"
     ]
    }
   ],
   "source": [
    "import collections\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def bfs(graph, root, goal):\n",
    "    visited = set()\n",
    "    queue = collections.deque([root])\n",
    "\n",
    "    while queue:\n",
    "        vertex = queue.popleft()\n",
    "        if vertex == goal:\n",
    "            print(f\"Goal {goal} found!\")\n",
    "            return\n",
    "        visited.add(vertex)\n",
    "        for i in graph[vertex]:\n",
    "            if i not in visited:\n",
    "                queue.append(i)\n",
    "    print(f\"Goal {goal} not found.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    graph = {0: [1, 2, 3], 1: [0, 2], 2: [0, 1, 4], 3: [0], 4: [2]}\n",
    "    bfs(graph, 0, 4)  # Change 4 to any goal node you want\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sure! Here's a **NumPy Practical Quiz** to test your skills. It's a mix of hands-on coding tasksâ€”just like you'd get in class or a practical exam.\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸ§ª NumPy Practical Quiz (Total Marks: 10)\n",
    "\n",
    "### ðŸ”¸ Q1. Create a 1D NumPy array with numbers from 10 to 50 (inclusive). (1 mark)\n",
    "\n",
    "---\n",
    "\n",
    "### ðŸ”¸ Q2. Create a 3Ã—3 NumPy array filled with random integers between 1 and 100. (1 mark)\n",
    "\n",
    "---\n",
    "\n",
    "### ðŸ”¸ Q3. Replace all even numbers in a NumPy array with -1. (2 marks)\n",
    "\n",
    "Example input: `np.array([10, 15, 20, 25])`  \n",
    "Expected output: `array([-1, 15, -1, 25])`\n",
    "\n",
    "---\n",
    "\n",
    "### ðŸ”¸ Q4. Given a 2D array, extract the second column. (2 marks)\n",
    "\n",
    "```python\n",
    "arr = np.array([\n",
    "    [5, 10, 15],\n",
    "    [20, 25, 30],\n",
    "    [35, 40, 45]\n",
    "])\n",
    "```\n",
    "\n",
    "Expected output: `[10 25 40]`\n",
    "\n",
    "---\n",
    "\n",
    "### ðŸ”¸ Q5. Create a NumPy array of shape (4, 4) and find the sum of each row. (2 marks)\n",
    "\n",
    "---\n",
    "\n",
    "### ðŸ”¸ Q6. Reshape a 1D array of 12 elements into a 3x4 2D array. (2 marks)\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸ“ Instructions:\n",
    "- Use `import numpy as np` at the start.\n",
    "- Write clean code.\n",
    "- Bonus if you print outputs with labels for clarity.\n",
    "\n",
    "---\n",
    "\n",
    "Would you like the **answer key** or prefer to try it first?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10 12 20 30 40]\n"
     ]
    }
   ],
   "source": [
    "data=np.array([10,12,20,30,40])\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[18 15 99]\n",
      " [20 41 48]\n",
      " [31  6 60]]\n"
     ]
    }
   ],
   "source": [
    "### ðŸ”¸ Q2. Create a 3Ã—3 NumPy array filled with random integers between 1 and 100. (1 mark)\n",
    "# arr=np.arange(9).reshape(3,3)\n",
    "arr2=np.random.randint(1,100,(3,3))\n",
    "print(arr2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10 25 40]\n"
     ]
    }
   ],
   "source": [
    "### ðŸ”¸ Q4. Given a 2D array, extract the second column. (2 marks)\n",
    "arr = np.array([\n",
    "    [5, 10, 15],\n",
    "    [20, 25, 30],\n",
    "    [35, 40, 45]\n",
    "])\n",
    "print(arr[:,1])\n",
    "\n",
    "# Expected output: `[10 25 40]`\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[24 28 32 36]\n"
     ]
    }
   ],
   "source": [
    "### ðŸ”¸ Q5. Create a NumPy array of shape (4, 4) and find the sum of each row. (2 marks)\n",
    "data=np.arange(16).reshape(4,4)\n",
    "data2=sum(data)\n",
    "print(data2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0  1  2  3]\n",
      " [ 4  5  6  7]\n",
      " [ 8  9 10 11]]\n"
     ]
    }
   ],
   "source": [
    "### ðŸ”¸ Q6. Reshape a 1D array of 12 elements into a 3x4 2D array. (2 marks)\n",
    "arr=np.arange(12)\n",
    "arr2=arr.reshape(3,4)\n",
    "print(arr2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 3 4 5 6 7 8]\n"
     ]
    }
   ],
   "source": [
    "arr=np.arange(9)\n",
    "print(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 1. 1.]\n",
      " [1. 1. 1.]\n",
      " [1. 1. 1.]]\n"
     ]
    }
   ],
   "source": [
    "arr2=np.ones((3,3))\n",
    "print(arr2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "arr3=np.eye(5,5)\n",
    "print(arr3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "random() takes at most 1 positional argument (2 given)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m arr4=\u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrandom\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrandom\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[32;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      2\u001b[39m \u001b[38;5;28mprint\u001b[39m(arr4)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mnumpy\\\\random\\\\mtrand.pyx:443\u001b[39m, in \u001b[36mnumpy.random.mtrand.RandomState.random\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mTypeError\u001b[39m: random() takes at most 1 positional argument (2 given)"
     ]
    }
   ],
   "source": [
    "arr4=np.random.random(1,10)\n",
    "print(arr4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
